boxplot(housing.df$CRIM ~ housing.df$CAT..MEDV,
xlab = "CAT.MEDV", ylab = "CRIM")
boxplot(housing.df$CRIM ~ housing.df$CAT..MEDV,
xlab = "CAT.MEDV", ylab = "CRIM", log = 'y')
options(scipen=999) # avoid scientific notation
## scatter plot: regular and log scale
plot(housing.df$MEDV ~ housing.df$CRIM, xlab = "CRIM", ylab = "MEDV")
# to use logarithmic scale set argument log = to either 'x', 'y', or 'xy'.
plot(housing.df$MEDV ~ housing.df$CRIM,
xlab = "CRIM", ylab = "MEDV", log = 'xy')
par(mfcol=c(2,1))
barplot(height = data.for.plot$meanMEDV[data.for.plot$CHAS==0],
names.arg = data.for.plot$RAD[data.for.plot$CHAS==0],
xlab = 'RAD', ylab='Avg. MEDV', main='CHAS =0'
)
barplot(height = data.for.plot$meanMEDV[data.for.plot$CHAS==1],
names.arg = data.for.plot$RAD[data.for.plot$CHAS==1],
xlab='RAD',ylab = 'Avg. MEDV', main='CHAS=1'
)
library(ggplot2)
ggplot(housing.df) + geom_point(aes(x=CRIM,y=MEDV))+
scale_x_log10(breaks = 10^(-2:2),
labels = format(10^(-2:2), scientific = FALSE, drop0trailing = TRUE)) +
scale_y_log10(breaks = c(5, 10, 20, 40))
#boxplot in log scale
boxplot(housing.df$CRIM~housing.df$CAT..MEDV)
boxplot(housing.df$CRIM~housing.df$CAT..MEDV,log=y)
boxplot(housing.df$CRIM~housing.df$CAT..MEDV,log='y')
#boxplot in log scale
boxplot(housing.df$CRIM~housing.df$CAT..MEDV)
boxplot(housing.df$CRIM~housing.df$CAT..MEDV,log='y')
ridership.ts <- ts(Amtrak.df$Ridership, start = c(1991, 1), end = c(2004, 3), freq = 12)
Amtrak.df <- read.csv("datasets//Amtrak data.csv")
Amtrak.df <- read.csv("datasets/Amtrak data.csv")
ridership.ts <- ts(Amtrak.df$Ridership, start = c(1991, 1), end = c(2004, 3), freq = 12)
#figure 3.9
#timeseries
library(forecast)
Amtrak.df <- read.csv("datasets/Amtrak data.csv")
ridership.ts <- ts(Amtrak.df$Ridership, start = c(1991, 1), end = c(2004, 3), freq = 12)
ridership.ts <- ts(Amtrak.df$Ridership, start = c(1991, 1), end = c(2004, 3), freq = 12)
plot(ridership.ts)
plot(ridership.ts.lm)
## fit curve
ridership.ts.lm=tslm(ridership.ts ~trend + I(trend^2))
plot(ridership.ts.lm)
plot(ridership.ts, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
plot(ridership.ts.lm)
## fit curve
ridership.ts.lm=tslm(ridership.ts ~trend + I(trend^2))
plot(ridership.ts.lm)
plot(ridership.ts.lm,ylim=c(1300,2300))
plot(ridership.ts.lm,xlab='',ylab='',ylim=c(1300,2300))
plot(ridership.ts,xlab='',ylab='',ylim=c(1300,2300))
line(ridership.ts.lm$fitted,lwd=2)
line(ridership.ts.lm$fitted,lwd=2)
line(ridership.ts.lm$fitted)
lines(ridership.lm$fitted, lwd = 2)
plot(ridership.ts, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
lines(ridership.lm$fitted, lwd = 2)
lines(ridership.ts.lm$fitted, lwd = 2)
Amtrak.df <- read.csv("datasets/Amtrak data.csv")
ridership.ts <- ts(Amtrak.df$Ridership, start = c(1991, 1), end = c(2004, 3), freq = 12)
## fit curve
ridership.ts.lm=tslm(ridership.ts ~trend + I(trend^2))
plot(ridership.ts, xlab = "", ylab = "", ylim = c(1300, 2300))
lines(ridership.ts.lm$fitted, lwd = 2)
# alternative plot with ggplot #But the curve is inverted U.
library(ggplot2)
ggplot(Amtrak.df, aes(y = Ridership, x = Month, group = 12)) +
geom_line() + geom_smooth(formula = y ~ poly(x, 2), method= "lm",
colour = "navy", se = FALSE, na.rm = TRUE)
ggplot(Amtrak.df, aes(y = Ridership, x = Month, group = 12)) +
geom_line() + geom_smooth(formula = y ~ poly(x, 2), method= "lm",
colour = "navy", se = FALSE, na.rm = TRUE)
# alternative plot with ggplot #But the curve is inverted U.
library(ggplot2)
ggplot(Amtrak.df, aes(y = Ridership, x = Month, group = 12)) +
geom_line() + geom_smooth(formula = y ~ poly(x, 2), method= "lm",
colour = "navy", se = FALSE, na.rm = TRUE)
library(ggplot2)
ggplot(Amtrak.df, aes(y = Ridership, x = Month, group = 12)) +
geom_line() + geom_smooth(formula = y ~ poly(x, 2), method= "lm",
colour = "navy", se = FALSE, na.rm = TRUE)
library(ggplot2)
ggplot(Amtrak.df, aes(y = Ridership, x = Month, group = 12)) +
geom_line() + geom_smooth(formula = y ~ poly(x, 2), method= "lm",
colour = "navy", se = FALSE, na.rm = TRUE)
library(ggplot2)
Amtrak.df <- read.csv("datasets/Amtrak data.csv")
ggplot(Amtrak.df, aes(y = Ridership, x = Month, group = 12)) +
geom_line() + geom_smooth(formula = y ~ poly(x, 2), method= "lm",
colour = "navy", se = FALSE, na.rm = TRUE)
#modifying x to handle appropriately
ggplot(amtrak.df, aes(y=ridership,x=as.numeric(time(ridership.ts)))) +geom_line() +
geom_smooth(formula=y~poly(x.2),method = 'lm' colour = "navy", se = FALSE, na.rm = TRUE) +
#modifying x to handle appropriately
ggplot(amtrak.df, aes(y=ridership,x=as.numeric(time(ridership.ts)))) +geom_line() +
geom_smooth(formula=y~poly(x.2),method = 'lm' ,colour = "navy", se = FALSE, na.rm = TRUE) +
xlab("Year") + ylab("Ridership (in 000s)")
#modifying x to handle appropriately
ggplot(Amtrak.df, aes(y=ridership,x=as.numeric(time(ridership.ts)))) +geom_line() +
geom_smooth(formula=y~poly(x.2),method = 'lm' ,colour = "navy", se = FALSE, na.rm = TRUE) +
xlab("Year") + ylab("Ridership (in 000s)")
ggplot(Amtrak.df, aes(y = Ridership, x = Month, group = 12)) +
geom_line() + geom_smooth(formula = y ~ poly(x, 2), method= "lm",
colour = "navy", se = FALSE, na.rm = TRUE)
#modifying x to handle appropriately
ggplot(Amtrak.df, aes(y=Ridership,x=as.numeric(time(ridership.ts)))) +geom_line() +
geom_smooth(formula=y~poly(x.2),method = 'lm' ,colour = "navy", se = FALSE, na.rm = TRUE) +
xlab("Year") + ylab("Ridership (in 000s)")
#modifying x to handle appropriately
ggplot(Amtrak.df, aes(y=Ridership,x=as.numeric(time(ridership.ts)))) +geom_line() +
geom_smooth(formula=y~poly(x,2),method = 'lm' ,colour = "navy", se = FALSE, na.rm = TRUE) +
xlab("Year") + ylab("Ridership (in 000s)")
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,1), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,1), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
monthly.ridership.ts <- tapply(ridership.ts, cycle(ridership.ts), mean)
plot(monthly.ridership.ts, xlab = "Month", ylab = "Average Ridership",
ylim = c(1300, 2300), type = "l", xaxt = 'n')
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,5), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,2), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,2), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
monthly.ridership.ts <- tapply(ridership.ts, cycle(ridership.ts), mean)
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,2), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,1), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,3), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
##zoom in, monthly and annual plots
ridership.2yrs <- window(ridership.ts, start = c(1991,1), end = c(1992,12))
plot(ridership.2yrs, xlab = "Year", ylab = "Ridership (in 000s)", ylim = c(1300, 2300))
# package forecast is required to evaluate performance
library(forecast)
set.seed(1)
# load file
toyota.corolla.df <- read.csv("Lecture 4/ToyotaCorolla.csv")
# load file
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
# load file
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
setwd("C:/Users/26amr/OneDrive - The University of Texas at Dallas/UTD/Fall 2024/Business ANalytics with R/model evaluation lecture 4")
# load file
toyota.corolla.df <- read.csv(" ToyotaCorolla.csv")
# load file
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
# randomly generate training and validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
toyota.corolla.df$Id
toyota.corolla.df
view(toyota.corolla.df)
view(toyota.corolla.df)
View(toyota.corolla.df)
# randomly generate training and validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
# run linear regression model
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,8,11)], subset=training,
na.action=na.exclude)
pred_t <- predict(reg, na.action=na.pass)
pred_v <- predict(reg, newdata=toyota.corolla.df[validation,-c(1,2,8,11)],
na.action=na.pass)
## evaluate performance
# training
accuracy(pred_t, toyota.corolla.df[training,]$Price)
# validation
accuracy(pred_v, toyota.corolla.df[validation,]$Price)
pred_v <- predict(reg, newdata=toyota.corolla.df[validation,-c(1,2,8,11)],
na.action=na.pass)
## evaluate performance
# training
accuracy(pred_t, toyota.corolla.df[training,]$Price)
# validation
accuracy(pred_v, toyota.corolla.df[validation,]$Price)
# randomly generate training and validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
# run linear regression model
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,8,11)], subset=training,
na.action=na.exclude)
pred_t <- predict(reg, na.action=na.pass)
pred_v <- predict(reg, newdata=toyota.corolla.df[validation,-c(1,2,8,11)],
na.action=na.pass)
## evaluate performance
# training
accuracy(pred_t, toyota.corolla.df[training,]$Price)
# validation
accuracy(pred_v, toyota.corolla.df[validation,]$Price)
# package forecast is required to evaluate performance
library(forecast)
set.seed(1)
# load file
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
View(toyota.corolla.df)
# randomly generate training and validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
# run linear regression model
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,8,11)], subset=training,
na.action=na.exclude)
pred_t <- predict(reg, na.action=na.pass)
pred_v <- predict(reg, newdata=toyota.corolla.df[validation,-c(1,2,8,11)],
na.action=na.pass)
## evaluate performance
# training
accuracy(pred_t, toyota.corolla.df[training,]$Price)
# validation
accuracy(pred_v, toyota.corolla.df[validation,]$Price)
##################
# Histogram and Boxplot of prediction errors
training_data <- toyota.corolla.df[training,]
validation_data <- toyota.corolla.df[validation,]
training_data$pred_t <- pred_t
validation_data$pred_v <- pred_v
training_data$error <- training_data$Price - training_data$pred_t
validation_data$error <- validation_data$Price - validation_data$pred_v
par(mfrow=c(1,2))
hist(training_data$error)
hist(validation_data$error)
boxplot(training_data$error)
boxplot(validation_data$error)
valdata <- toyota.corolla.df[validation,]
##################
valdata
# remove missing Price data
toyota.corolla.df <-
toyota.corolla.df[!is.na(toyota.corolla.df[validation,]$Price),]
# generate random Training and Validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(toyota.corolla.df$Id, 400)
# generate random Training and Validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(toyota.corolla.df$Id, 400)
# regression model based on all numerical predictors
reg <- lm(Price~., data = toyota.corolla.df[,-c(1,2,8,11)], subset = training)
# predictions
pred_v <- predict(reg, newdata = toyota.corolla.df[validation,-c(1,2,8,11)])
# load package gains, compute gains (we will use package caret for categorical y later)
library(gains)
gain <- gains(toyota.corolla.df[validation,]$Price[!is.na(pred_v)], pred_v[!is.na(pred_v)])
# cumulative lift chart
options(scipen=999) # avoid scientific notation
# First extract non-missing prices
price <- toyota.corolla.df[validation,]$Price[!is.na(toyota.corolla.df[validation,]$Price)]
plot(c(0,gain$cume.pct.of.total*sum(price))~c(0,gain$cume.obs),
xlab="# cases", ylab="Cumulative Price", main="Lift Chart", type="l")
# baseline
lines(c(0,sum(price))~c(0,dim(toyota.corolla.df[validation,])[1]), col="gray", lty=2)
# Decile-wise lift chart
barplot(gain$mean.resp/mean(price), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response", main = "Decile-wise lift chart")
# cumulative lift chart
options(scipen=999) # avoid scientific notation
# First extract non-missing prices
price <- toyota.corolla.df[validation,]$Price[!is.na(toyota.corolla.df[validation,]$Price)]
plot(c(0,gain$cume.pct.of.total*sum(price))~c(0,gain$cume.obs),
xlab="# cases", ylab="Cumulative Price", main="Lift Chart", type="l")
# baseline
lines(c(0,sum(price))~c(0,dim(toyota.corolla.df[validation,])[1]), col="gray", lty=2)
# Decile-wise lift chart
barplot(gain$mean.resp/mean(price), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response", main = "Decile-wise lift chart")
#### Table 5.5
#install future.apply --- future.apply_1.11.0.tar.gz
library(caret)
#### Table 5.5
#install future.apply --- future.apply_1.11.0.tar.gz
library(caret, pos = 'future.apply_1.11.0.tar.gz')
library(e1071)
owner.df <- read.csv("Lecture 4/ownerExample.csv")
owner.df <- read.csv("ownerExample.csv")
owner.df$Class <- as.factor(owner.df$Class)
#ConfusionMatrix(predicted, actual)
confusionMatrix(as.factor(ifelse(owner.df$Probability>0.5, 'owner', 'nonowner')),
owner.df$Class)
confusionMatrix(as.factor(ifelse(owner.df$Probability>0.25, 'owner', 'nonowner')),
owner.df$Class)
confusionMatrix(as.factor(ifelse(owner.df$Probability>0.75, 'owner', 'nonowner')),
owner.df$Class)
ggplot(owner.df)
ggplot(owner.df$Class) +
#### Figure 5.4
# replace data.frame with your own
df <- read.csv("Lecture 4/liftExample.csv")
ggplot(owner.df$Class)
ggplot(owner.df$Class)
ggplot(owner.df)
owner.df$Class <- as.factor(owner.df$Class)
#ConfusionMatrix(predicted, actual)
confusionMatrix(as.factor(ifelse(owner.df$Probability>0.5, 'owner', 'nonowner')),
owner.df$Class)
#ConfusionMatrix(predicted, actual)
pre=confusionMatrix(as.factor(ifelse(owner.df$Probability>0.5, 'owner', 'nonowner')),
owner.df$Class)
ggplot(pre)
heatmap(pre)
pre
heatmap(pre$table)
heatmap(pre$table,Rowv = NA)
heatmap(pre$table,Rowv = NA,Colv = NA)
ggplot(pre$table)
ggplot(pre$table)
ggplot(melt(pre$table))
pre.melt=melt(pre$table)
ggplot(melt(pre$table))
ggplot(pre$table)
ggplot(pre$table)
pre.melt
pre$table
# replace data.frame with your own
df <- read.csv("liftExample.csv")
# create empty accuracy table
accT = c()
# compute accuracy per cutoff
for (cut in seq(0,1,0.1)){
cm <- confusionMatrix(as.factor(1 * (df$prob > cut)), as.factor(df$actual))
accT = c(accT, cm$overall[1])
}
# plot accuracy
plot(accT ~ seq(0,1,0.1), xlab = "Cutoff Value", ylab = "", type = "l", ylim = c(0, 1))
lines(1-accT ~ seq(0,1,0.1), type = "l", lty = 2)
legend("topright",  c("accuracy", "overall error"), lty = c(1, 2), merge = TRUE)
# create empty accuracy table
accT = c()
# compute accuracy per cutoff
for (cut in seq(0,1,0.1)){
cm <- confusionMatrix(as.factor(1 * (df$prob > cut)), as.factor(df$actual))
accT = c(accT, cm$overall[1])
}
# plot accuracy
plot(accT ~ seq(0,1,0.1), xlab = "Cutoff Value", ylab = "", type = "l", ylim = c(0, 1))
lines(1-accT ~ seq(0,1,0.1), type = "l", lty = 2)
library(pROC)
r <- roc(df$actual, df$prob)
#### Figure 5.5
install.packages(pROC)
library(pROC)
r <- roc(df$actual, df$prob)
plot.roc(r)
# compute auc
auc(r)
# first option with 'caret' library:
library(caret)
lift.example <- lift(relevel(as.factor(actual), ref="1") ~ prob, data = df)
xyplot(lift.example, plot = "gain")
library(pROC)
r <- roc(df$actual, df$prob)
plot.roc(r)
library(pROC)
#### Figure 5.5
install.packages(pROC)
library(pROC)
r <- roc(df$actual, df$prob)
plot.roc(r)
# compute auc
auc(r)
# first option with 'caret' library:
library(caret)
lift.example <- lift(relevel(as.factor(actual), ref="1") ~ prob, data = df)
xyplot(lift.example, plot = "gain")
# first option with 'caret' library:
library(caret)
lift.example <- lift(relevel(as.factor(actual), ref="1") ~ prob, data = df)
xyplot(lift.example, plot = "gain")
# Second option with 'gains' library:
library(gains)
df <- read.csv("Lecture 4/liftExample.csv")
df <- read.csv("liftExample.csv")
gain <- gains(df$actual, df$prob, groups=dim(df)[1])
plot(c(0, gain$cume.pct.of.total*sum(df$actual)) ~ c(0, gain$cume.obs),
xlab = "# cases", ylab = "Cumulative", type="l")
lines(c(0,sum(df$actual))~c(0,dim(df)[1]), col="gray", lty=2)
gain <- gains(df$actual, df$prob)
barplot(gain$mean.resp / mean(df$actual), names.arg = gain$depth, xlab = "Percentile",
ylab = "Mean Response", main = "Decile-wise lift chart")
# first option with 'caret' library:
library(caret)
lift.example <- lift(relevel(as.factor(actual), ref="1") ~ prob, data = df)
xyplot(lift.example, plot = "gain")
# load file
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
# randomly generate training and validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
# run linear regression model
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,8,11)], subset=training,
na.action=na.exclude)
# randomly generate training and validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
# run linear regression model
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,8,11)], subset=training,
na.action=na.exclude)
pred_t <- predict(reg, na.action=na.pass)
pred_v <- predict(reg, newdata=toyota.corolla.df[validation,-c(1,2,8,11)],
na.action=na.pass)
## evaluate performance
# training
accuracy(pred_t, toyota.corolla.df[training,]$Price)
# package forecast is required to evaluate performance
library(forecast)
## evaluate performance
# training
accuracy(pred_t, toyota.corolla.df[training,]$Price)
# validation
accuracy(pred_v, toyota.corolla.df[validation,]$Price)
#### Figure 5.5
install.packages(pROC)
library(pROC)
library(pROC)
r <- roc(df$actual, df$prob)
plot.roc(r)
# compute auc
auc(r)
library(forecast)
set.seed(1)
toyoto.df=read.csv('ToyotaCorolla.csv')
head(toyoto.df)
training=sample(toyoto.df$Id,600)
validation=sample(setdiff(toyoto.df$Id,training),400)
#run linear regression model
reg=lm(Price~.,data=toyoto.df[,-c(1,2,8,11)], subset = training,na.action =na.exclude)
pred_t=predict(reg,na.action = na.pass)
pred_v=predict(reg,newdata = toyoto.df[validation,-c(1,2,8,11)],na.action = na.pass)
pred_v
accuracy(pred_t,toyoto.df[training,]$Price)
accuracy(pred_v,toyoto.df[validation,]$Price)
#Histogram and Boxplot of prediction erros
training_data=toyoto.df[training,]
validation_data=toyoto.df[validation,]
training_data$pred_t=pred_t
validation_data$pred_v=pred_v
training_data$error=training_data$Price-training_data$pred_t
#View(training_data)
validation_data$error=validation_data$Price-validation_data$pred_v
View(validation_data)
par(mfrow=c(1,2))
#histogram for error ranges
hist(training_data$error)
hist(validation_data$error)
#boxplots
boxplot(training_data$error)
boxplot(validation_data$error)
#methods to remove missing values
valdata=toyoto.df[validation,]
valdata
toyota.corolla.df=toyoto.df[!is.na(toyoto.df[validation,]$Price),]
# generate random Training and Validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(toyota.corolla.df$Id, 400)
reg <- lm(Price~., data = toyota.corolla.df[,-c(1,2,8,11)], subset = training)
pred_v <- predict(reg, newdata = toyota.corolla.df[validation,-c(1,2,8,11)])
#package gains - effectiveness of the model
library(gains)
gain=gains(toyota.corolla.df[validation,]$Price[!is.na(pred_v)],pred_v[!is.na(pred_v)])
gain
options(scipen = 999)
price=toyoto.df[validation,]$Price[!is.na(toyoto.df[validation,]$Price)]
plot(c(0,gain$cume.pct.of.total*sum(price))~c(0,gain$cume.obs),  xlab = "Percentile", ylab = "Mean Response", main='Lift Chart', type='l')
# baseline
lines(c(0,sum(price))~c(0,dim(toyota.corolla.df[validation,])[1]), col="gray", lty=2)
library(caret, pos = 'future.apply_1.11.0.tar.gz')
library(e1071)
library(reshape)
owner.df=read.csv('ownerExample.csv')
owner.df$Class=as.factor(owner.df$Class)
pre=confusionMatrix(as.factor(ifelse(owner.df$Probability>0.5, 'owner', 'nonowner')),
owner.df$Class)
confusionMatrix(as.factor(ifelse(owner.df$Probability>0.25, 'owner', 'nonowner')),
owner.df$Class)
confusionMatrix(as.factor(ifelse(owner.df$Probability>0.75, 'owner', 'nonowner')),
pre.melt <- melt(pre$table))
# Convert the melted confusion matrix to a data frame
pre.melt <- as.data.frame(pre.melt)
# Plot the confusion matrix using ggplot2
heatmap(pre$table)
ggplot(pre$table)
pre$table
df <- read.csv("liftExample.csv")
ggplot(pre$table)
# create empty accuracy table
accT = c()
# compute accuracy per cutoff
for (cut in seq(0,1,0.1)){
cm <- confusionMatrix(as.factor(1 * (df$prob > cut)), as.factor(df$actual))
accT = c(accT, cm$overall[1])
}
# plot accuracy
plot(accT ~ seq(0,1,0.1), xlab = "Cutoff Value", ylab = "", type = "l", ylim = c(0, 1))
lines(1-accT ~ seq(0,1,0.1), type = "l", lty = 2)
legend("topright",  c("accuracy", "overall error"), lty = c(1, 2), merge = TRUE)
#### Figure 5.5
install.packages(pROC)
library(pROC)
r <- roc(df$actual, df$prob)
plot.roc(r)
df
