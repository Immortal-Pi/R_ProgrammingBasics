print('Hello', quote=False)
print('Hello', quote=FALSE)
housing.df <- read.csv("Lecture 2/WestRoxbury.csv", header = TRUE)  # load data
housing.df <- read.csv("Lecture 2/WestRoxbury.csv", header = TRUE)  # load data
housing.df <- read.csv("WestRoxbury.csv", header = TRUE)  # load data
housing.df <- read.csv("D:/Education/R programming/R_Projects/Basics/WestRoxbury.csv", header = TRUE)  # load data
dim(housing.df)  # find the dimension of data frame
View(housing.df)  # show all the data in a new tab
# Practice showing different subsets of the data
housing.df[1:10, 1]  # show the first 10 rows of the first column only
# Practice showing different subsets of the data
housing.df[1:10, 1]  # show the first 10 rows of the first column only
housing.df[1:10, ]  # show the first 10 rows of each of the columns
housing.df[5, c(1:2, 4, 8:10)]  # show the fifth row of some columns
housing.df$TOTAL.VALUE  # a different way to show the whole first column
length(housing.df$TOTAL.VALUE)  # find the length of the first column
summary(housing.df)  # find summary statistics for each column
housing.df[]
# random sample of 5 observations
s <- sample(row.names(housing.df), 5)
s
housing.df[s,]
names(housing.df)  # print a list of variables to the screen.
#names(housing.df) retrieves the column names of the housing.df dataframe.
#t(names(housing.df)) transposes the vector of column names, which doesn't change anything since it's already a vector.
#t(t(names(housing.df))) then transposes the transposed vector, which brings it back to the original state.
t(t(names(housing.df)))  # print the list in a useful column format
View(housing.df)  # show all the data in a new tab
dim(housing.df)  # find the dimension of data frame
# Practice showing different subsets of the data
housing.df[1:10, 1]  # show the first 10 rows of the first column only
housing.df[1:10, ]  # show the first 10 rows of each of the columns
housing.df[5, 1:10]  # show the fifth row of the first 10 columns
housing.df[5, c(1:2, 4, 8:10)]  # show the fifth row of some columns
housing.df[5, c(1:2, 4, 8:10)]  # show the fifth row of some columns
housing.df[5, c(1:2, 4, 8:10)]  # show the fifth row of some columns
housing.df[, 1]  # show the whole first column
housing.df$TOTAL.VALUE  # a different way to show the whole first column
housing.df$TOTAL.VALUE[1:10]  # show the first 10 rows of the first column
length(housing.df$TOTAL.VALUE)  # find the length of the first column
summary(housing.df)  # find summary statistics for each column
# random sample of 5 observations
s <- sample(row.names(housing.df), 5)
housing.df[s,]
# oversample houses with over 10 rooms
s <- sample(row.names(housing.df), 5, prob = ifelse(housing.df$ROOMS>10, 0.9, 0.01))
names(housing.df)  # print a list of variables to the screen.
#names(housing.df) retrieves the column names of the housing.df dataframe.
#t(names(housing.df)) transposes the vector of column names, which doesn't change anything since it's already a vector.
#t(t(names(housing.df))) then transposes the transposed vector, which brings it back to the original state.
t(t(names(housing.df)))  # print the list in a useful column format
colnames(housing.df)[1] <- c("TOTAL_VALUE")  # change the first column's name
housing.df$REMODEL <- as.factor(housing.df$REMODEL)
class(housing.df[ ,14]) # Same.
levels(housing.df[, 14])  # It can take one of three levels
class(housing.df$BEDROOMS)  # BEDROOMS is an integer variable
class(housing.df[, 1])  # Total_Value is a numeric variable
#### Table 2.6
# Option 1: use dummies package
# dummies_1.5.6.tar.gz - download from http://cran.nexr.com/web/packages/dummies/index.html
install.packages(dummies)
#### Table 2.6
# Option 1: use dummies package
# dummies_1.5.6.tar.gz - download from http://cran.nexr.com/web/packages/dummies/index.html
install.packages(dummies)
library(dummies)
#### Table 2.6
# Option 1: use dummies package
# dummies_1.5.6.tar.gz - download from http://cran.nexr.com/web/packages/dummies/index.html
install.packages(dummies)
##housing.df <- dummy.data.frame(housing.df, sep = ".")  Original row, does not work
housing.df <- dummy.data.frame(housing.df, names = "REMODEL" , sep = ".")
library(dummies)
#### Table 2.6
# Option 1: use dummies package
# dummies_1.5.6.tar.gz - download from http://cran.nexr.com/web/packages/dummies/index.html
install.packages(dummies)
library(dummies)
# Option 2: use model.matrix() to convert all categorical variables in the data frame into a set of dummy variables.
# We must then turn the resulting data matrix back into a data frame for further work.
xtotal <- model.matrix(~ 0 + BEDROOMS + REMODEL, data = housing.df)
xtotal$BEDROOMS[1:5] # will not work because xtotal is a matrix
xtotal <- as.data.frame(xtotal)
t(t(names(xtotal)))  # check the names of the dummy variables
install.packages("dummies")
install.packages("dummy")
library(dummy)
#### Table 2.6
# Option 1: use dummies package
# dummies_1.5.6.tar.gz - download from http://cran.nexr.com/web/packages/dummies/index.html
install.packages("dummy")
library(dummy)
##housing.df <- dummy.data.frame(housing.df, sep = ".")  Original row, does not work
housing.df <- dummy.data.frame(housing.df, names = "REMODEL" , sep = ".")
##housing.df <- dummy.data.frame(housing.df, sep = ".")  Original row, does not work
housing.df <- dummy.(housing.df, names = "REMODEL" , sep = ".")
library(dummy)
##housing.df <- dummy.data.frame(housing.df, sep = ".")  Original row, does not work
housing.df <- dummy.(housing.df, names = "REMODEL" , sep = ".")
##housing.df <- dummy.data.frame(housing.df, sep = ".")  Original row, does not work
housing.df <- dummy(housing.df, names = "REMODEL" , sep = ".")
##housing.df <- dummy.data.frame(housing.df, sep = ".")  Original row, does not work
housing.df <- dummy(housing.df, names = "REMODEL")
# To illustrate missing data procedures, we first convert a few entries for
# bedrooms to NA's. Then we impute these missing values using the median of the
# remaining values.
rows.to.missing <- sample(row.names(housing.df), 10)
housing.df[rows.to.missing,]$BEDROOMS <- NA
# replace the missing values using the median of the remaining values.
# use median() with na.rm = TRUE to ignore missing values when computing the median.
housing.df[rows.to.missing,]$BEDROOMS <- median(housing.df$BEDROOMS, na.rm = TRUE)
summary(housing.df$BEDROOMS)
# use set.seed() to get the same partitions when re-running the R code.
set.seed(1)
## partitioning into training (60%) and validation (40%)
# randomly sample 60% of the row IDs for training; the remaining 40% serve as
# validation
train.rows <- sample(rownames(housing.df), dim(housing.df)[1]*0.6)
# collect all the columns with training row ID into training set:
train.data <- housing.df[train.rows, ]
# assign row IDs that are not already in the training set, into validation
valid.rows <- setdiff(rownames(housing.df), train.rows)
valid.data <- housing.df[valid.rows, ]
# alternative code for validation (works only when row names are numeric):
# collect all the columns without training row ID into validation set
valid.data <- housing.df[-train.rows, ] # does not work in this case
## partitioning into training (50%), validation (30%), test (20%)
# randomly sample 50% of the row IDs for training
train.rows <- sample(rownames(housing.df), dim(housing.df)[1]*0.5)
dim(housing.df)  # find the dimension of data frame
train.rows
view(train.rows)
View(train.rows)
# collect all the columns with training row ID into training set:
train.data <- housing.df[train.rows, ]
train.data
# assign row IDs that are not already in the training set, into validation
valid.rows <- setdiff(rownames(housing.df), train.rows)
valid.data <- housing.df[valid.rows, ]
# alternative code for validation (works only when row names are numeric):
# collect all the columns without training row ID into validation set
valid.data <- housing.df[-train.rows, ] # does not work in this case
## partitioning into training (50%), validation (30%), test (20%)
# randomly sample 50% of the row IDs for training
train.rows <- sample(rownames(housing.df), dim(housing.df)[1]*0.5)
train.rpws
train.rows
train.rows
# sample 30% of the row IDs into the validation set, drawing only from records
# not already in the training set
# use setdiff() to find records not already in the training set
valid.rows <- sample(setdiff(rownames(housing.df), train.rows),
dim(housing.df)[1]*0.3)
# assign the remaining 20% row IDs serve as test
test.rows <- setdiff(rownames(housing.df), union(train.rows, valid.rows))
# create the 3 data frames by collecting all columns from the appropriate rows
train.data <- housing.df[train.rows, ]
valid.data <- housing.df[valid.rows, ]
test.data <- housing.df[test.rows, ]
reg <- lm(TOTAL_VALUE ~ .-TAX, data = housing.df, subset = train.rows) # remove variable "TAX"
tr.res <- data.frame(train.data$TOTAL_VALUE, reg$fitted.values, reg$residuals)
head(tr.res)
pred <- predict(reg, newdata = valid.data)
vl.res <- data.frame(valid.data$TOTAL_VALUE, pred, residuals =
valid.data$TOTAL_VALUE - pred)
head(vl.res)
#### Table 2.13
#installed.packages()
#install.packages("pkgconfig")
#install.packages("curl")
#install.packages("forecast")
library(forecast)
# compute accuracy on training set
accuracy(reg$fitted.values, train.data$TOTAL_VALUE)
pred <- predict(reg, newdata = valid.data)
vl.res <- data.frame(valid.data$TOTAL_VALUE, pred, residuals =
valid.data$TOTAL_VALUE - pred)
head(vl.res)
# compute accuracy on training set
accuracy(reg$fitted.values, train.data$TOTAL_VALUE)
# compute accuracy on prediction set
pred <- predict(reg, newdata = valid.data)
accuracy(pred, valid.data$TOTAL_VALUE)
#d -ii]
heatmap.2(
house.df.mat,
cellnote = round(house.df.mat,2),
notecol = 'black',
trace='none',
density.info = 'none',
dendrogram = 'none',
col=bluered(100),
margins = c(10,10),
breaks = seq(-1,1,length.out=101)
)
library(gplots)
#d -ii]
heatmap.2(
house.df.mat,
cellnote = round(house.df.mat,2),
notecol = 'black',
trace='none',
density.info = 'none',
dendrogram = 'none',
col=bluered(100),
margins = c(10,10),
breaks = seq(-1,1,length.out=101)
)
house.df=read.csv('BostonHousing.csv')
setwd("C:/Users/26amr/OneDrive - The University of Texas at Dallas/UTD/Fall 2024/Business ANalytics with R/assignment 3")
house.df=read.csv('BostonHousing.csv')
head(house.df)
set.seed(1)
train.index=sample(c(1:length(house.df$CRIM)),length(house.df$CRIM)*0.60)
house.df.train=house.df[train.index,]
house.df.valid=house.df[-train.index,]
house.df.lm=lm(MEDV~CRIM+CHAS+RM,data = house.df.train)
summary(house.df.lm)
#house.df.pred=predict(house.df.lm,house.df.valid)
#house.df.pred
house.df.lm
formula=house.df.lm$coefficients['(Intercept)']+house.df.lm$coefficients['CRIM']*0.1+house.df.lm$coefficients['CHAS']*0+house.df.lm$coefficients['RM']*6
formula
#colnames(house.df)
library(dplyr)
result=filter(house.df,RM >= 6 & RM<6.99 & CRIM==0.1 & CHAS==0)$MEDV
result
#formula
prediction_error=result-as.numeric(formula)
prediction_error
#d - i]
options(scipen = 999)
library(gplots)
house.df.mat=cor(house.df[,-c(14)])
# View(house.df[,-c(14)])
cor(house.df[,c(3,5,10)])
unique(house.df$RAD)
#d -ii]
heatmap.2(
house.df.mat,
cellnote = round(house.df.mat,2),
notecol = 'black',
trace='none',
density.info = 'none',
dendrogram = 'none',
col=bluered(100),
margins = c(10,10),
breaks = seq(-1,1,length.out=101)
)
summary(house.df.lm)
new_data=data.frame(0.1,0,6)
new_data=data.frame(CRIM=0.1,CHAS=0,RM=6)
result=predict(reg,newdata = new_data,se.fit = TRUE)
house.df=read.csv('BostonHousing.csv')
head(house.df)
set.seed(1)
train.index=sample(c(1:length(house.df$CRIM)),length(house.df$CRIM)*0.60)
house.df.train=house.df[train.index,]
house.df.valid=house.df[-train.index,]
house.df.lm=lm(MEDV~CRIM+CHAS+RM,data = house.df.train)
summary(house.df.lm)
#house.df.pred=predict(house.df.lm,house.df.valid)
#house.df.pred
house.df.lm
formula=house.df.lm$coefficients['(Intercept)']+house.df.lm$coefficients['CRIM']*0.1+house.df.lm$coefficients['CHAS']*0+house.df.lm$coefficients['RM']*6
formula
#colnames(house.df)
library(dplyr)
new_data=data.frame(CRIM=0.1,CHAS=0,RM=6)
result=predict(reg,newdata = new_data,se.fit = TRUE)
result=predict(house.df.lm,newdata = new_data,se.fit = TRUE)
result
result$fit
print('error'+as.numeric(result$fit))
print('error'+as.numeric(result$fit))
print('error'+as.character(result$fit))
print('error',as.numeric(result$fit))
paste('error:',as.numeric(result$fit))
paste('error:',as.numeric(result$se.fit))
train.index=sample(c(1:length(house.df$CRIM)),length(house.df$CRIM)*0.70)
house.df.train=house.df[train.index,]
house.df.valid=house.df[-train.index,]
house.df.lm=lm(MEDV~CRIM+CHAS+RM,data = house.df.train)
summary(house.df.lm)
#house.df.pred=predict(house.df.lm,house.df.valid)
#house.df.pred
house.df.lm
formula=house.df.lm$coefficients['(Intercept)']+house.df.lm$coefficients['CRIM']*0.1+house.df.lm$coefficients['CHAS']*0+house.df.lm$coefficients['RM']*6
formula
#colnames(house.df)
library(dplyr)
new_data=data.frame(CRIM=0.1,CHAS=0,RM=6)
result=predict(house.df.lm,newdata = new_data,se.fit = TRUE)
paste('error:',as.numeric(result$se.fit))
#formula
prediction_error=result-as.numeric(formula)
house.df.lm$coefficients
new_observation=data.frame(CRIM=0.1,CHAS=0,RM=6)
result=predict(house.df.lm,newdata = new_observation)
paste('error:',as.numeric(result$se.fit))
result
result
new_observation=data.frame(CRIM=0.1,CHAS=0,RM=6)
result=predict(house.df.lm,newdata = new_observation)
result
print(result)
result=predict(house.df.lm,newdata = new_observation)
print(result)
formula
summary(house.df.lm)
formula=house.df.lm$coefficients['(Intercept)']+house.df.lm$coefficients['CRIM']*0.1+house.df.lm$coefficients['CHAS']*0+house.df.lm$coefficients['RM']*6
formula
result=predict(house.df.lm,newdata = new_observation)
print(result)
result=predict(house.df.lm,newdata = new_observation,se.fit = TRUE)
print(result)
print(result$se.fit)
print('error:',result$se.fit)
paste('error:',result$se.fit)
summary(house.df.lm)
#house.df.pred=predict(house.df.lm,house.df.valid)
#house.df.pred
house.df.lm
#d - i]
options(scipen = 999)
library(gplots)
house.df.mat=cor(house.df[,-c(14)])
# View(house.df[,-c(14)])
cor(house.df[,c(3,5,10)])
unique(house.df$RAD)
#d -ii]
heatmap.2(
house.df.mat,
cellnote = round(house.df.mat,2),
notecol = 'black',
trace='none',
density.info = 'none',
dendrogram = 'none',
col=bluered(100),
margins = c(10,10),
breaks = seq(-1,1,length.out=101)
)
colnames(house.df)
house.df.updated=house.df[,-c(3,5,10)]
colnames(house.df.updated)
train.index=sample(c(1:length(house.df$CRIM)),length(house.df$CRIM)*0.70)
house.df.train.updated=house.df.updated[train.index,]
house.df.valid.updated=house.df.updated[-train.index,]
full_model=lm(MEDV ~.,data = house.df.train.updated)
# backward model
backward_model=step(full_model,direction = 'backward')
summary(backward_model)
#forward model
forward_model=step(full_model,direction = 'forward',scope = formula(full_model))
summary(forward_model)
#both model
both_model=step(full_model,direction = 'both')
summary(both_model)
## prediction
backwards_pred=predict(backward_model,newdata = house.df.valid.updated)
forward_pred=predict(forward_model,newdata = house.df.valid.updated)
both_pred=predict(both_model,newdata = house.df.valid.updated)
house.df.valid.updated$back_prob=backwards_pred
house.df.valid.updated$forw_prob=forward_pred
house.df.valid.updated$both_prob=both_pred
#house.df.valid.updated$CAT.MEDV=ifelse(house.df.valid.updated$MEDV>median(house.df.valid.updated$MEDV),1,0)
# Calculate performance metrics
calc_metrics <- function(actual, predicted) {
rmse <- RMSE(actual,predicted)
mape <- mape(actual,predicted)
mean_error <- mean(actual-predicted)
return(c(RMSE = rmse, MAPE = mape, Mean_Error = mean_error))
}
#difference
backward_metrics=calc_metrics(house.df.valid.updated$MEDV,backwards_pred)
forward_metrics=calc_metrics(house.df.valid.updated$MEDV,forward_pred)
both_metrics=calc_metrics(house.df.valid.updated$MEDV,both_pred)
metrics.df=data.frame(
Model=c('backward','forward','both'),
RMSE=c(backward_metrics[1],forward_metrics[1],both_metrics[1]),
MAPE=c(backward_metrics[2],forward_metrics[2],both_metrics[2]),
Mean_Error=c(backward_metrics[3],forward_metrics[3],both_metrics[3])
)
library(caret)
print(metrics.df)
metrics.df=data.frame(
Model=c('backward','forward','both'),
RMSE=c(backward_metrics[1],forward_metrics[1],both_metrics[1]),
MAPE=c(backward_metrics[2],forward_metrics[2],both_metrics[2]),
Mean_Error=c(backward_metrics[3],forward_metrics[3],both_metrics[3])
)
library(caret)
print(metrics.df)
#difference
backward_metrics=calc_metrics(house.df.valid.updated$MEDV,backwards_pred)
library(caret)
#difference
backward_metrics=calc_metrics(house.df.valid.updated$MEDV,backwards_pred)
#dataset - Boston Housing
# predict :- median house pricing [MEDV]
# crime rate, pollution, number of rooms
library(MASS)
library(ggplot2)
library(caret)
library(Metrics)
## prediction
backwards_pred=predict(backward_model,newdata = house.df.valid.updated)
forward_pred=predict(forward_model,newdata = house.df.valid.updated)
both_pred=predict(both_model,newdata = house.df.valid.updated)
house.df.valid.updated$back_prob=backwards_pred
house.df.valid.updated$forw_prob=forward_pred
house.df.valid.updated$both_prob=both_pred
#house.df.valid.updated$CAT.MEDV=ifelse(house.df.valid.updated$MEDV>median(house.df.valid.updated$MEDV),1,0)
# Calculate performance metrics
calc_metrics <- function(actual, predicted) {
rmse <- RMSE(actual,predicted)
mape <- mape(actual,predicted)
mean_error <- mean(actual-predicted)
return(c(RMSE = rmse, MAPE = mape, Mean_Error = mean_error))
}
#difference
backward_metrics=calc_metrics(house.df.valid.updated$MEDV,backwards_pred)
forward_metrics=calc_metrics(house.df.valid.updated$MEDV,forward_pred)
both_metrics=calc_metrics(house.df.valid.updated$MEDV,both_pred)
metrics.df=data.frame(
Model=c('backward','forward','both'),
RMSE=c(backward_metrics[1],forward_metrics[1],both_metrics[1]),
MAPE=c(backward_metrics[2],forward_metrics[2],both_metrics[2]),
Mean_Error=c(backward_metrics[3],forward_metrics[3],both_metrics[3])
)
library(caret)
print(metrics.df)
#house.df.valid.updated$CAT..MEDV <- levels(as.factor(house.df.valid.updated$CAT.MEDV))
lift.backward=lift(relevel(as.factor(house.df.valid.updated$CAT..MEDV),ref = 1)~house.df.valid.updated$back_prob)
xyplot(lift.backward,plot='gain')
lift.forward=lift(relevel(as.factor(house.df.valid.updated$CAT..MEDV),ref = 1)~house.df.valid.updated$forw_prob)
xyplot(lift.forward,plot='gain')
lift.both=lift(relevel(as.factor(house.df.valid.updated$CAT..MEDV),ref = 1)~house.df.valid.updated$both_prob)
paste('prediction error:',result$se.fit)
formula=house.df.lm$coefficients['(Intercept)']+house.df.lm$coefficients['CRIM']*0.1+house.df.lm$coefficients['CHAS']*0+house.df.lm$coefficients['RM']*6
formula
#colnames(house.df)
library(dplyr)
new_observation=data.frame(CRIM=0.1,CHAS=0,RM=6)
result=predict(house.df.lm,newdata = new_observation,se.fit = TRUE)
paste('prediction error:',result$se.fit)
#d - i]
options(scipen = 999)
formula=house.df.lm$coefficients['(Intercept)']+house.df.lm$coefficients['CRIM']*0.1+house.df.lm$coefficients['CHAS']*0+house.df.lm$coefficients['RM']*6
formula
#colnames(house.df)
library(dplyr)
new_observation=data.frame(CRIM=0.1,CHAS=0,RM=6)
result=predict(house.df.lm,newdata = new_observation,se.fit = TRUE)
paste('prediction error:',result$se.fit)
